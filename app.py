# app.py
# ‚úàÔ∏è VNA Tech ‚Äì Tra c·ª©u t√†i li·ªáu t·ª´ Google Drive (PDF/PPTX)
# T√°c v·ª•: ƒê·ªìng b·ªô Drive -> chunking -> embedding -> cache (.pkl) -> truy h·ªìi Top-K -> tr·∫£ l·ªùi.

import os, json, hashlib, pickle, tempfile
from collections.abc import Mapping
from typing import Dict, Any, List, Tuple

import numpy as np
import streamlit as st
import tiktoken
from pypdf import PdfReader
from pptx import Presentation
from openai import OpenAI

from pydrive2.auth import GoogleAuth
from pydrive2.drive import GoogleDrive

# ================== C·∫•u h√¨nh chung ==================
APP_TITLE = "‚úàÔ∏è VNA Tech: H·ªó tr·ª£ tra c·ª©u th√¥ng tin t√†i li·ªáu t·ª´ Google Drive"
EMBED_MODEL = "text-embedding-3-small"   # 1536 chi·ªÅu
EMBED_DIM = 1536
CHUNK_TOKENS = 400
CHUNK_OVERLAP = 80
TOP_K = 10
META_PATH = "embeddings_meta.pkl"        # cache ch√≠nh (metadata + embeddings + texts)
# ====================================================


# ----------------- Helpers: Secrets -----------------
def require_secret(key: str) -> str:
    val = st.secrets.get(key) or os.getenv(key)
    if not val:
        st.error(f"Thi·∫øu {key} trong Secrets."); st.stop()
    return val

def load_gsa_secrets() -> Dict[str, Any]:
    """
    ƒê·ªçc GOOGLE_SERVICE_ACCOUNT_JSON d∆∞·ªõi d·∫°ng:
    - Mapping (TOML object) -> tr·∫£ v·ªÅ dict
    - String JSON (triple quotes '''...''' ho·∫∑c """...""") -> json.loads
    """
    raw = st.secrets.get("GOOGLE_SERVICE_ACCOUNT_JSON", None)
    if raw is None:
        st.error("Thi·∫øu GOOGLE_SERVICE_ACCOUNT_JSON trong Secrets."); st.stop()

    if isinstance(raw, Mapping):
        return dict(raw)  # TOML object

    if isinstance(raw, str):
        try:
            return json.loads(raw)  # JSON string
        except Exception:
            st.error("GOOGLE_SERVICE_ACCOUNT_JSON kh√¥ng ph·∫£i JSON h·ª£p l·ªá. Ki·ªÉm tra triple quotes v√† gi·ªØ nguy√™n k√Ω t·ª± \\n trong private_key.")
            st.stop()

    st.error(f"GOOGLE_SERVICE_ACCOUNT_JSON c√≥ ki·ªÉu kh√¥ng h·ªó tr·ª£: {type(raw).__name__}")
    st.stop()


# ----------------- Google Drive -----------------
def get_drive(creds_dict: Dict[str, Any]) -> GoogleDrive:
    """Kh·ªüi t·∫°o GoogleDrive d√πng service account qua settings (truy·ªÅn client_json l√† dict)."""
    gauth = GoogleAuth(settings={
        "client_config_backend": "service",
        "service_config": {"client_json": creds_dict},
        "save_credentials": False,
    })
    gauth.ServiceAuth()  # kh√¥ng truy·ªÅn tham s·ªë -> d√πng settings ·ªü tr√™n
    return GoogleDrive(gauth)

def list_drive_files(drive: GoogleDrive, folder_id: str) -> List[Dict[str, Any]]:
    # H·ªó tr·ª£ PDF v√† PPTX; b·∫≠t include All Drives cho Shared Drive
    q = (
        f"'{folder_id}' in parents and trashed=false and ("
        "mimeType='application/pdf' or "
        "mimeType='application/vnd.openxmlformats-officedocument.presentationml.presentation'"
        ")"
    )
    files = drive.ListFile({
        "q": q,
        "supportsAllDrives": True,
        "includeItemsFromAllDrives": True
    }).GetList()
    return [
        {
            "id": f["id"],
            "title": f["title"],
            "mimeType": f["mimeType"],
            "modifiedDate": f.get("modifiedDate"),
            "md5Checksum": f.get("md5Checksum"),
        }
        for f in files
    ]

def download_drive_file(drive: GoogleDrive, file_id: str, local_path: str) -> str:
    f = drive.CreateFile({"id": file_id})
    f.GetContentFile(local_path)
    return local_path


# ----------------- X·ª≠ l√Ω t√†i li·ªáu & embedding -----------------
def md5_of_file(path: str) -> str:
    h = hashlib.md5()
    with open(path, "rb") as fp:
        for chunk in iter(lambda: fp.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()

def read_pdf(path: str) -> List[Tuple[int, str]]:
    out = []
    reader = PdfReader(path)
    for i, p in enumerate(reader.pages, start=1):
        txt = p.extract_text() or ""
        out.append((i, txt))
    return out

def read_pptx(path: str) -> List[Tuple[int, str]]:
    prs = Presentation(path)
    out = []
    for i, slide in enumerate(prs.slides, start=1):
        parts = [sh.text for sh in slide.shapes if hasattr(sh, "text")]
        out.append((i, " ".join(parts)))
    return out

def token_chunks(text: str, max_tokens=CHUNK_TOKENS, overlap=CHUNK_OVERLAP, enc_name="cl100k_base") -> List[str]:
    enc = tiktoken.get_encoding(enc_name)
    toks = enc.encode(text)
    chunks, i, n = [], 0, len(toks)
    while i < n:
        j = min(i + max_tokens, n)
        chunks.append(enc.decode(toks[i:j]))
        if j == n: break
        i = j - overlap
    return chunks

def get_openai_client() -> OpenAI:
    return OpenAI(api_key=require_secret("OPENAI_API_KEY"))

def embed_texts(client: OpenAI, texts: List[str]) -> np.ndarray:
    if not texts: return np.zeros((0, EMBED_DIM), dtype=np.float32)
    r = client.embeddings.create(model=EMBED_MODEL, input=texts)
    vecs = [d.embedding for d in r.data]
    return np.array(vecs, dtype=np.float32)

def l2_normalize(X: np.ndarray) -> np.ndarray:
    n = np.linalg.norm(X, axis=1, keepdims=True) + 1e-10
    return X / n


# ----------------- Cache embeddings_meta.pkl -----------------
# C·∫•u tr√∫c:
# {
#   "dim": 1536,
#   "files": { <file_id>: {"title":..., "md5":..., "ranges":[(start,end)]} },
#   "embeddings": np.ndarray (N,dim)  -- ƒë√£ chu·∫©n ho√°,
#   "texts": List[str]  -- song h√†nh v·ªõi embeddings
# }
def load_meta(path=META_PATH):
    if os.path.exists(path):
        with open(path, "rb") as f: return pickle.load(f)
    return {"dim": EMBED_DIM, "files": {}, "embeddings": np.zeros((0, EMBED_DIM), dtype=np.float32), "texts": []}

def save_meta(meta, path=META_PATH):
    with open(path, "wb") as f: pickle.dump(meta, f)

def sync_from_drive(drive: GoogleDrive, folder_id: str):
    """ƒê·ªìng b·ªô: ch·ªâ x·ª≠ l√Ω file m·ªõi/ƒë·ªïi, sau ƒë√≥ c·∫≠p nh·∫≠t embeddings_meta.pkl"""
    client = get_openai_client()
    meta = load_meta()
    files = list_drive_files(drive, folder_id)
    added = 0

    for f in files:
        fid, title = f["id"], f["title"]

        with tempfile.TemporaryDirectory() as td:
            local = os.path.join(td, title)
            download_drive_file(drive, fid, local)
            md5_now = md5_of_file(local)

            # B·ªè qua n·∫øu ch∆∞a thay ƒë·ªïi
            if fid in meta["files"] and meta["files"][fid]["md5"] == md5_now:
                continue

            # ƒê·ªçc & chunk
            pages = read_pdf(local) if title.lower().endswith(".pdf") else read_pptx(local)
            chunks = []
            for _, txt in pages:
                chunks.extend(token_chunks(txt))

            # Embedding & chu·∫©n ho√°
            vecs = embed_texts(client, chunks)
            vecs = l2_normalize(vecs)

            # Append v√†o cache
            start = meta["embeddings"].shape[0]
            if vecs.shape[0] > 0:
                meta["embeddings"] = np.vstack([meta["embeddings"], vecs])
                meta["texts"].extend(chunks)
            end = meta["embeddings"].shape[0]

            meta["files"][fid] = {"title": title, "md5": md5_now, "ranges": [(start, end)]}
            added += (end - start)

    if added > 0: save_meta(meta)
    return meta

def retrieve_top_k(query: str, meta, k=TOP_K) -> List[Tuple[float, str, str]]:
    client = get_openai_client()
    q = embed_texts(client, [query])
    q = l2_normalize(q)[0]  # (dim,)
    M = meta["embeddings"]
    if M.shape[0] == 0: return []

    sims = M @ q  # cosine (ƒë√£ chu·∫©n ho√°)
    idx = np.argsort(-sims)[:k]

    # √°nh x·∫° index -> file title
    file_by_index = {}
    for fid, finfo in meta["files"].items():
        title = finfo["title"]
        for (s, e) in finfo["ranges"]:
            for i in range(s, e):
                file_by_index[i] = title

    results = []
    for i in idx:
        results.append((float(sims[i]), file_by_index.get(int(i), "unknown"), meta["texts"][int(i)]))
    return results

def answer_from_chunks(query: str, chunks: List[str]) -> str:
    client = get_openai_client()
    context = "\n\n".join(chunks)
    r = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω k·ªπ thu·∫≠t. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch·ªâ d·ª±a tr√™n CONTEXT."},
            {"role": "user", "content": f"CONTEXT:\n{context}\n\nC√ÇU H·ªéI: {query}\n\nN·∫øu thi·∫øu d·ªØ li·ªáu, h√£y n√™u r√µ."}
        ],
        temperature=0.2
    )
    return r.choices[0].message.content


# ----------------- UI -----------------
st.set_page_config(page_title="VNA Tech ‚Äì Tra c·ª©u t√†i li·ªáu", page_icon="‚úàÔ∏è", layout="wide")
st.title(APP_TITLE)

# Secrets t·ªëi thi·ªÉu
DRIVE_FOLDER_ID = require_secret("DRIVE_FOLDER_ID")
creds_dict = load_gsa_secrets()  # h·ªó tr·ª£ c·∫£ string JSON l·∫´n object TOML

with st.sidebar:
    st.subheader("Thi·∫øt l·∫≠p")
    st.write("‚Ä¢ Ngu·ªìn: Google Drive (th∆∞ m·ª•c ƒë√£ chia s·∫ª cho Service Account).")
    if st.button("üîÑ ƒê·ªìng b·ªô Drive ‚Üí Cache (.pkl)"):
        with st.spinner("ƒêang ƒë·ªìng b·ªô d·ªØ li·ªáu t·ª´ Google Drive..."):
            drive = get_drive(creds_dict)
            meta_after = sync_from_drive(drive, DRIVE_FOLDER_ID)
            st.success(f"ƒê·ªìng b·ªô xong. T·ªïng vector: {meta_after['embeddings'].shape[0]}")

st.markdown("‚Äî")
query = st.text_input("ƒê·∫∑t c√¢u h·ªèi:")
if st.button("T√¨m c√¢u tr·∫£ l·ªùi") and query:
    drive = get_drive(creds_dict)
    meta = sync_from_drive(drive, DRIVE_FOLDER_ID)  # ch·ªâ x·ª≠ l√Ω file m·ªõi/ƒë·ªïi
    if meta["embeddings"].shape[0] == 0:
        st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu trong cache. H√£y b·∫•m 'ƒê·ªìng b·ªô Drive ‚Üí Cache (.pkl)'."); st.stop()

    hits = retrieve_top_k(query, meta, k=TOP_K)
    if not hits:
        st.info("Kh√¥ng t√¨m th·∫•y ƒëo·∫°n li√™n quan."); st.stop()

    st.subheader("üîü C√°c ƒëo·∫°n li√™n quan")
    chunks = []
    for score, title, chunk in hits:
        st.markdown(f"**[{title}]** ‚Äî score={score:.3f}")
        st.write((chunk[:800] + "...") if len(chunk) > 800 else chunk)
        st.markdown("---")
        chunks.append(chunk)

    st.subheader("‚ú® Tr·∫£ l·ªùi")
    st.write(answer_from_chunks(query, chunks))
